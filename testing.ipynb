{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad089e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import InMemoryRunner, Runner\n",
    "from google.adk.sessions import  InMemorySessionService\n",
    "from google.adk.tools import AgentTool, FunctionTool, google_search, BaseTool\n",
    "from google.genai import types\n",
    "\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "from pathlib import Path    \n",
    "from typing import Literal, Optional, Dict, Any, Final\n",
    "\n",
    "\n",
    "\n",
    "print(\"✅ ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27057c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings from ADK and Gemini APIs\n",
    "logging.getLogger(\"google.adk.runners\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"google_genai.types\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82d6060a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded GEMINI_API_KEY.\n"
     ]
    }
   ],
   "source": [
    "# This line loads the environment variables from your .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access the variables using os.getenv()\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if gemini_api_key:\n",
    "    print(\"Successfully loaded GEMINI_API_KEY.\")\n",
    "    # You can now use the gemini_api_key variable to configure your API client\n",
    "    # print(f\"API Key: {gemini_api_key[:4]}...{gemini_api_key[-4:]}\") # Example of printing a redacted key\n",
    "else:\n",
    "    print(\"Error: GEMINI_API_KEY not found. Make sure it's in your .env file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d33ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config=types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=2,  # Delay multiplier\n",
    "    initial_delay=5,\n",
    "    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eeb36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional, Final\n",
    "\n",
    "# Import necessary ADK components\n",
    "from google.adk.plugins import BasePlugin\n",
    "from google.adk.sessions import Session\n",
    "from google.adk.agents.invocation_context import InvocationContext\n",
    "\n",
    "# --- Configuration & Constants ---\n",
    "SESSION_DIARY_PATH: Final[Path] = Path(\"data/session_diary.json\")\n",
    "GEMINI_MODEL: Final[str] = \"gemini-2.5-flash\"\n",
    "MAX_RETRIES: Final[int] = 3\n",
    "\n",
    "# --- JSON Schema for Structured Output ---\n",
    "# This is the standard JSON Schema used to force the LLM to return reliable JSON.\n",
    "SUMMARY_SCHEMA: Final[Dict[str, Any]] = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"last_daily_focus\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"A short sentence capturing the main virtue/lesson/focus from the DAILY cluster session, if one occurred.\"\n",
    "        },\n",
    "        \"last_weekly_goal\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"A short sentence describing the main goal, reflection, or virtue defined in the WEEKLY cluster session, if one occurred.\"\n",
    "        },\n",
    "        \"long_term_objective\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"A concise statement of the user's primary long-term objective mentioned in the session, if one was set or discussed.\"\n",
    "        },\n",
    "        \"on_demand_diary_note\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"A short, narrative diary note (max 50 words) summarizing the most important reactive (ON-DEMAND) interaction, including the core problem and the philosophical advice given.\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"last_daily_focus\", \"last_weekly_goal\", \"long_term_objective\", \"on_demand_diary_note\"]\n",
    "}\n",
    "\n",
    "# --- Utility Functions ---\n",
    "\n",
    "def _get_text_from_event(event: Any) -> str:\n",
    "    \"\"\"Safely extracts and formats text from an event's content structure.\"\"\"\n",
    "    if not hasattr(event, 'content') or not event.content or not hasattr(event.content, 'parts'):\n",
    "        return \"\"\n",
    "    \n",
    "    parts = []\n",
    "    for part in event.content.parts:\n",
    "        if hasattr(part, 'text') and part.text:\n",
    "            parts.append(part.text.strip())\n",
    "        # Add handling for other part types if needed (e.g., function_call)\n",
    "    \n",
    "    return \" | \".join(parts)\n",
    "\n",
    "def _generate_transcript(events: List[Any]) -> str:\n",
    "    \"\"\"Generates a readable conversation transcript from session events.\"\"\"\n",
    "    transcript = []\n",
    "    for i, event in enumerate(events):\n",
    "        text = _get_text_from_event(event)\n",
    "        role = \"USER\" if i == 0 else \"AGENT\"\n",
    "        if text:\n",
    "            transcript.append(f\"[{role}]: {text}\")\n",
    "    return \"\\n\".join(transcript)\n",
    "\n",
    "def _load_diary() -> List[Dict[str, Any]]:\n",
    "    \"\"\"Loads existing diary entries safely.\"\"\"\n",
    "    if SESSION_DIARY_PATH.exists():\n",
    "        with open(SESSION_DIARY_PATH, 'r') as f:\n",
    "            try:\n",
    "                # Load the full list of previous session logs\n",
    "                return json.load(f)\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Warning: Could not decode JSON in diary file. Starting with empty diary.\")\n",
    "                return []\n",
    "    return []\n",
    "\n",
    "def _save_diary(diary: List[Dict[str, Any]]):\n",
    "    \"\"\"Saves the updated diary entries.\"\"\"\n",
    "    with open(SESSION_DIARY_PATH, 'w') as f:\n",
    "        json.dump(diary, f, indent=2)\n",
    "\n",
    "async def _call_gemini_for_summary(transcript: str, session_id: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    STUB FUNCTION: Call the Gemini API for structured summarization.\n",
    "    \n",
    "    *** IMPORTANT: YOU MUST REPLACE THIS STUB WITH YOUR ASYNCHRONOUS HTTP CLIENT CALL. ***\n",
    "    \n",
    "    This function outlines the required payload structure for the Gemini API.\n",
    "    \"\"\"\n",
    "    print(f\"\\t[LLM Call]: Preparing to summarize session {session_id}...\")\n",
    "    \n",
    "    # 1. Construct the System Prompt\n",
    "    system_prompt = (\n",
    "        \"You are a highly efficient memory compression and extraction service. \"\n",
    "        \"Your task is to analyze the session transcript and extract the most \"\n",
    "        \"relevant information into the STRICT JSON format provided in the schema.\"\n",
    "    )\n",
    "    \n",
    "    # 2. Construct the User Query (including the transcript)\n",
    "    user_query = (\n",
    "        \"### Session Transcript\\n\"\n",
    "        f\"{transcript}\\n\\n\"\n",
    "        \"### Task\\n\"\n",
    "        \"Analyze the transcript and generate the required structured JSON summary.\"\n",
    "    )\n",
    "\n",
    "    # 3. Define the full API payload\n",
    "    payload = {\n",
    "        \"contents\": [{\"parts\": [{\"text\": user_query}]}],\n",
    "        \"systemInstruction\": {\"parts\": [{\"text\": system_prompt}]},\n",
    "        \"generationConfig\": {\n",
    "            \"responseMimeType\": \"application/json\",\n",
    "            \"responseSchema\": SUMMARY_SCHEMA,\n",
    "            \"temperature\": 0.1 # Low temperature for reliable structure\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # --- STUB IMPLEMENTATION BELOW ---\n",
    "    # In a real ADK environment, you would use an async library (like httpx)\n",
    "    # and exponential backoff to make the POST request to the Gemini API.\n",
    "    \n",
    "    # MOCKING THE RESPONSE for local testing:\n",
    "    if \"quitting my stable job\" in transcript:\n",
    "        return {\n",
    "            \"last_daily_focus\": \"\",\n",
    "            \"last_weekly_goal\": \"Investigate financial viability of artistic pursuits.\",\n",
    "            \"long_term_objective\": \"Transition to a full-time artistic career.\",\n",
    "            \"on_demand_diary_note\": \"User faced fear about career change; advised on existential freedom and necessity of choice (DeBeauvoir).\"\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"last_daily_focus\": \"Successfully mediated conflict with a structured, scientific approach.\",\n",
    "            \"last_weekly_goal\": \"\",\n",
    "            \"long_term_objective\": \"Improve personal communication skills.\",\n",
    "            \"on_demand_diary_note\": \"Roommate conflict resolved using Dewey's scientific method of hypothesis testing and evaluation.\"\n",
    "        }\n",
    "    # --- STUB IMPLEMENTATION END ---\n",
    "\n",
    "# --- The Plugin ---\n",
    "\n",
    "class SessionPersistencePlugin(BasePlugin):\n",
    "    \"\"\"\n",
    "    Plugin to handle custom persistence by summarizing the session content \n",
    "    using a Gemini LLM call and saving the results to a local diary file.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name: str = \"session_persistence_plugin\"):\n",
    "        \"\"\"Initialize the plugin and ensure the data directory exists.\"\"\"\n",
    "        super().__init__(name)\n",
    "        SESSION_DIARY_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # NOTE: In a real app, initialize your async HTTP client here\n",
    "        \n",
    "        print(f\"[Plugin Init]: Ready to write session data to: {SESSION_DIARY_PATH}\")\n",
    "        \n",
    "    def _load_diary(self) -> List[Dict[str, Any]]:\n",
    "        return _load_diary()\n",
    "\n",
    "    def _save_diary(self, diary: List[Dict[str, Any]]):\n",
    "        _save_diary(diary)\n",
    "\n",
    "    async def after_run_callback(\n",
    "        self, \n",
    "        *, \n",
    "        invocation_context: InvocationContext\n",
    "    ) -> Optional[None]:\n",
    "        \"\"\"\n",
    "        Executes after the entire Runner process completes.\n",
    "        Calls an LLM to generate a structured summary, then saves it.\n",
    "        \"\"\"\n",
    "        session = invocation_context.session \n",
    "        session_id = session.id\n",
    "        print(f\"\\n[AFTER_RUN Hook]: Starting summary and auto-save for ID: {session_id}\")\n",
    "        \n",
    "        try:\n",
    "            # 1. Extract the full session transcript\n",
    "            transcript = _generate_transcript(session.events)\n",
    "            \n",
    "            # 2. Call LLM to get the structured summary (JSON)\n",
    "            summary_data = await _call_gemini_for_summary(transcript, session_id)\n",
    "            \n",
    "            # 3. Extract necessary metadata\n",
    "            user_query = _get_text_from_event(session.events[0]) if session.events else \"N/A\"\n",
    "            final_response_text = _get_text_from_event(session.events[-1]) if session.events else \"N/A\"\n",
    "            \n",
    "            # 4. Assemble the final session log entry\n",
    "            log_entry: Dict[str, Any] = {\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"session_id\": session_id,\n",
    "                \"user_id\": session.user_id,\n",
    "                \"user_query\": user_query,\n",
    "                \"final_response_text\": final_response_text,\n",
    "                \n",
    "                # Merge the LLM-generated summary keys directly into the log\n",
    "                **summary_data, \n",
    "                \n",
    "                # We can still include the raw final state for completeness/debugging\n",
    "                \"raw_final_state\": session.state.to_dict() if hasattr(session.state, 'to_dict') else str(session.state)\n",
    "            }\n",
    "\n",
    "            # 5. Load, append, and save\n",
    "            diary = self._load_diary()\n",
    "            diary.append(log_entry)\n",
    "            self._save_diary(diary)\n",
    "                \n",
    "            print(\"[AFTER_RUN Hook]: Successfully generated summary and saved log entry.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[AFTER_RUN Hook ERROR]: Failed to generate summary or save session {session_id}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List, Final\n",
    "# We need to import the context object used by the low-level hook\n",
    "from google.adk.agents.invocation_context import InvocationContext\n",
    "# We need types.Content to safely parse content, but since we cannot reliably import \n",
    "# internal types, we will rely on duck-typing the context objects.\n",
    "# We will still use BasePlugin and Session for context.\n",
    "from google.adk.plugins import BasePlugin\n",
    "\n",
    "# --- Utility Function for Safe Extraction (Revised to use invocation_context data) ---\n",
    "\n",
    "def _get_text_from_event(event: Any) -> str:\n",
    "    \"\"\"Safely extracts text from an event's content structure.\"\"\"\n",
    "    \n",
    "    # We must check for content/parts structure which is what the ADK uses for message bodies\n",
    "    if not hasattr(event, 'content') or not event.content or not hasattr(event.content, 'parts'):\n",
    "        return \"\"\n",
    "    \n",
    "    parts = []\n",
    "    for part in event.content.parts:\n",
    "        if hasattr(part, 'text') and part.text:\n",
    "            parts.append(part.text.strip())\n",
    "        elif hasattr(part, 'function_call') and part.function_call:\n",
    "             parts.append(f\"Function Call: {part.function_call.name}\")\n",
    "        elif hasattr(part, 'function_response') and part.function_response:\n",
    "             parts.append(f\"Function Response: {part.function_response.name}\")\n",
    "    \n",
    "    return \" | \".join(parts)\n",
    "\n",
    "# --- The Plugin ---\n",
    "\n",
    "class SessionPersistencePlugin(BasePlugin):\n",
    "    \"\"\"\n",
    "    A custom plugin using the standard method-name hook to capture session data \n",
    "    after the runner finishes.\n",
    "    \"\"\"\n",
    "    def __init__(self, name: str = \"session_persistence_plugin\"):\n",
    "        \"\"\"\n",
    "        Initialize the session persistence plugin and ensure the data directory exists.\n",
    "        \n",
    "        Args:\n",
    "          name: The name of the plugin instance, passed to BasePlugin.\n",
    "        \"\"\"\n",
    "        # CRITICAL FIX: Call the BasePlugin constructor with the required name argument\n",
    "        super().__init__(name)\n",
    "        \n",
    "        # Ensure the directory exists when the plugin is initialized\n",
    "        SESSION_DIARY_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"[Plugin Init]: Ready to write session data to: {SESSION_DIARY_PATH}\")\n",
    "\n",
    "    def _load_diary(self) -> List[Dict[str, Any]]:\n",
    "        # ... (Same safe loading logic as before) ...\n",
    "        if SESSION_DIARY_PATH.exists():\n",
    "            with open(SESSION_DIARY_PATH, 'r') as f:\n",
    "                try:\n",
    "                    return json.load(f)\n",
    "                except json.JSONDecodeError:\n",
    "                    return []\n",
    "        return []\n",
    "\n",
    "    def _save_diary(self, diary: List[Dict[str, Any]]):\n",
    "        # ... (Same saving logic as before) ...\n",
    "        with open(SESSION_DIARY_PATH, 'w') as f:\n",
    "            json.dump(diary, f, indent=2)\n",
    "\n",
    "    # The required method name for the after-run hook (no decorator used)\n",
    "    async def after_run_callback(\n",
    "        self, \n",
    "        *, \n",
    "        invocation_context: InvocationContext\n",
    "    ) -> Optional[None]:\n",
    "        \"\"\"\n",
    "        Executes after the entire Runner process completes, capturing the final state.\n",
    "        We access the final session object via the invocation_context.\n",
    "        \"\"\"\n",
    "        # The session is available within the InvocationContext for post-run hooks\n",
    "        session = invocation_context.session \n",
    "        \n",
    "        print(f\"\\n[AFTER_RUN Hook]: Starting session auto-save for ID: {session.id}\")\n",
    "        \n",
    "        try:\n",
    "            # 1. Extract necessary data\n",
    "            \n",
    "            # The user's query is typically the first event's content\n",
    "            user_query = _get_text_from_event(session.events[0]) if session.events else \"N/A\"\n",
    "            \n",
    "            # The final response is the last event's content\n",
    "            final_response_text = _get_text_from_event(session.events[-1]) if session.events else \"N/A\"\n",
    "            \n",
    "            # If session.state is dict-like, use this:\n",
    "            final_state_dict = dict(session.state.items()) if hasattr(session.state, 'items') else {} \n",
    "            \n",
    "            # If the SessionState object is iterable:\n",
    "            if not final_state_dict and hasattr(session.state, '__iter__'):\n",
    "                final_state_dict = {k: v for k, v in session.state}\n",
    "            \n",
    "            session_data: Dict[str, Any] = {\n",
    "                # ... (rest of the session_data dict) ...\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"session_id\": session.id,\n",
    "                \"user_id\": session.user_id,\n",
    "                \"user_query\": user_query,\n",
    "                \"final_state\": final_state_dict,\n",
    "                \"final_response_text\": final_response_text\n",
    "            }\n",
    "\n",
    "            # 2. Load, append, and save\n",
    "            diary = self._load_diary()\n",
    "            diary.append(session_data)\n",
    "            self._save_diary(diary)\n",
    "                \n",
    "            print(\"[AFTER_RUN Hook]: Successfully saved session data.\")\n",
    "                \n",
    "            print(\"[AFTER_RUN Hook]: Successfully saved session data.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[AFTER_RUN Hook ERROR]: Failed to save session {session.id}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bcfdeb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the app_name, user_id and session_id for testing the agents\n",
    "APP_NAME = \"agents\"\n",
    "USER_ID = \"user_1\"\n",
    "\n",
    "\n",
    "async def test_agent(query, agent):\n",
    "  \"\"\"Sends a query to the agent and prints the final response.\"\"\"\n",
    "  session_service = InMemorySessionService()\n",
    "\n",
    "\n",
    "  print(f\"\\n>>> User Query: {query}\")\n",
    "\n",
    "  unique_session_id = str(uuid.uuid4()) \n",
    "\n",
    "\n",
    "  # Create a session\n",
    "  session = await session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=unique_session_id # Pass the unique ID\n",
    "  )\n",
    "\n",
    "  # Create a Runner\n",
    "  runner = Runner(\n",
    "      app_name=APP_NAME,\n",
    "      agent=agent,\n",
    "      session_service=session_service,\n",
    "      plugins=[SessionPersistencePlugin()],\n",
    "  )\n",
    "\n",
    "  # Prepare the user's message in ADK format\n",
    "  content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "\n",
    "  final_response_text = None\n",
    "  # We iterate through events from run_async to find the final answer.\n",
    "  async for event in runner.run_async(user_id=USER_ID, session_id=session.id, new_message=content):\n",
    "      if event.is_final_response():\n",
    "          if event.content and event.content.parts:\n",
    "             final_response_text = event.content.parts[0].text\n",
    "          break\n",
    "  return f\"<<< Agent Response: {final_response_text}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac7aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_DIR = Path(\"the_teams\")\n",
    "TEAM_NAMES = {\n",
    "    \"daily\": \"daily\",\n",
    "    \"weekly\": \"weekly\",\n",
    "    \"long_term\": \"long_term\",\n",
    "    \"on_demand\": \"on_demand\",\n",
    "    \"oracle\": \"oracle\"\n",
    "}\n",
    "\n",
    "TEAM_NAMES.keys()\n",
    "\n",
    "ALL_TEAM_ROUTERS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d513a416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(filename: str) -> Dict[str, Any]:\n",
    "    \"\"\"Loads a JSON configuration file.\"\"\"\n",
    "    try:\n",
    "        with open(CONFIG_DIR / f\"{filename}.json\", 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Configuration file not found at {CONFIG_DIR / f'{filename}.json'}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6da67427",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_LLM = model=Gemini(\n",
    "    model=\"gemini-2.0-flash-lite\",\n",
    "    api_key=gemini_api_key,\n",
    "    retry_options=retry_config\n",
    "    )\n",
    "router_LLM = model=Gemini(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key=gemini_api_key,\n",
    "    retry_options=retry_config\n",
    "    )\n",
    "\n",
    "def define_agents(team_name) -> Agent:\n",
    "    \"\"\"\n",
    "    Defines the complete three-tiered agent architecture:\n",
    "    RootRouter (Tier 1) -> Cluster Routers (Tier 2) -> Specialist Agents (Tier 3)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 5a. TIER 3: SPECIALIST AGENTS ---\n",
    "    # These agents are grouped by the cluster they belong to, but we create unique instances\n",
    "    # for all 13 agents.\n",
    "\n",
    "    agent_list = []\n",
    "    \n",
    "    # Collect all unique agent names across all four levels\n",
    "    descriptions = load_config(f\"{team_name}_descriptions\")\n",
    "    all_agent_names = list(descriptions.keys())\n",
    "    instructions = load_config(f\"{team_name}_instructions\")\n",
    "\n",
    "\n",
    "    # Create the unique instance for each specialist (Tier 3)\n",
    "    for agent_name in all_agent_names:\n",
    "        if agent_name != team_name:\n",
    "            print(agent_name)\n",
    "            #print(descriptions[agent_name])\n",
    "            #print(instructions[agent_name])\n",
    "        # All specialist agents get the memory tool\n",
    "            output_key = f\"{team_name}_response_by_{agent_name}\"\n",
    "            current_agent =  Agent(\n",
    "                name=agent_name,\n",
    "                description=descriptions[agent_name],\n",
    "                model=agent_LLM,\n",
    "                instruction=instructions[agent_name],\n",
    "                output_key=output_key,\n",
    "                #tools=[memory_tool] # Pass the shared memory tool to the specialist\n",
    "            )\n",
    "            agent_list.append(current_agent)\n",
    "\n",
    "\n",
    "    agents_as_tools = [AgentTool(agent) for agent in agent_list]        \n",
    "    \n",
    "    output_key = f\"{team_name}_response_by_{team_name}\"\n",
    "\n",
    "    router_agent = Agent(\n",
    "            name=team_name,\n",
    "            description=descriptions[team_name],\n",
    "            model=router_LLM,\n",
    "            instruction=instructions[team_name],\n",
    "            output_key=output_key,\n",
    "            tools = agents_as_tools # Pass the shared memory tool to the specialist\n",
    "        )\n",
    "    return router_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0f8f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily\n",
      "Camus\n",
      "Seneca\n",
      "Epicurus\n",
      "Aristotle\n",
      "Nagarjuna\n",
      "Socrates\n",
      "DeBeauvoir\n",
      "Hooks\n",
      "weekly\n",
      "Aristotle\n",
      "DeBeauvoir\n",
      "Hooks\n",
      "Kant\n",
      "Nagarjuna\n",
      "Nietzsche\n",
      "Nussbaum\n",
      "Dewey\n",
      "long_term\n",
      "DeBeauvoir\n",
      "Nietzsche\n",
      "Nussbaum\n",
      "Aristotle\n",
      "Dewey\n",
      "Nagarjuna\n",
      "on_demand\n",
      "Confucius\n",
      "Socrates\n",
      "DeBeauvoir\n",
      "Seneca\n",
      "Kant\n",
      "Aristotle\n",
      "Epicurus\n",
      "Dewey\n",
      "Camus\n",
      "Nussbaum\n"
     ]
    }
   ],
   "source": [
    "TEAM_NAMES = {\n",
    "    \"daily\": \"daily\",\n",
    "    \"weekly\": \"weekly\",\n",
    "    \"long_term\": \"long_term\",\n",
    "    \"on_demand\": \"on_demand\",\n",
    "    \"oracle\": \"oracle\"\n",
    "}\n",
    "\n",
    "for team in TEAM_NAMES:\n",
    "    if team != \"oracle\":\n",
    "        print(team)\n",
    "        ALL_TEAM_ROUTERS[team] = define_agents(team)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7822775a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confucius\n",
      "Socrates\n",
      "DeBeauvoir\n",
      "Seneca\n",
      "Kant\n",
      "Aristotle\n",
      "Epicurus\n",
      "Dewey\n",
      "Camus\n",
      "Nussbaum\n",
      "--- Running tests from the_teams/on_demand_queries.json ---\n",
      "\n",
      "--- Testing: Confucius ---\n",
      "\n",
      ">>> User Query: I need to write an email to respectfully decline a request from a superior. How should I phrase it?\n",
      "[Plugin Init]: Ready to write session data to: data/session_diary.json\n",
      "\n",
      "[AFTER_RUN Hook]: Starting session auto-save for ID: 0dd28b9f-764c-4609-8c76-a4f05f444d14\n",
      "[AFTER_RUN Hook]: Successfully saved session data.\n",
      "[AFTER_RUN Hook]: Successfully saved session data.\n",
      "<<< Agent Response: Analyze your situation with diligence. To decline a request from a superior is a matter of utmost importance. Your role is one of a subordinate, and your duty is to fulfill requests to the best of your ability. However, when you cannot, you must decline with both clarity and respect.\n",
      "\n",
      "Begin by expressing gratitude for the opportunity. State your inability to fulfill the request directly and honestly, but frame it as a constraint, not a refusal. Offer an alternative, if possible, or suggest how you might still be of service. Always end by reaffirming your commitment to your role and the overall well-being of the organization.\n",
      "\n",
      "For example, you might say, \"Thank you for considering me for this task. While I am unable to take on this particular responsibility at this time due to prior commitments, I would be pleased to assist in any other way I can.\"\n",
      "\n",
      "The essence of harmony in this exchange lies in your sincerity, respect, and your willingness to maintain the bonds of a functional society.\n",
      "\n",
      "Remember this: To respectfully decline is not a weakness, but a demonstration of *Ren* and *Li*. Always prioritize respect, clarity, and dedication to your duty. In modern terms: Be grateful, be honest about why you can't do something, offer to help in another way if you can, and always show you care. This builds trust and strengthens the relationship.\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Socrates ---\n",
      "\n",
      ">>> User Query: What is the true nature of 'success' in a modern context?\n",
      "[Plugin Init]: Ready to write session data to: data/session_diary.json\n",
      "\n",
      "[AFTER_RUN Hook]: Starting session auto-save for ID: 80906671-6da9-48e1-9a56-27967ff3ad50\n",
      "[AFTER_RUN Hook]: Successfully saved session data.\n",
      "[AFTER_RUN Hook]: Successfully saved session data.\n",
      "<<< Agent Response: So, you seek to understand 'success.' Tell me, what do you believe constitutes success? Is it wealth, power, recognition, or something else entirely?\n",
      "\n",
      "If it is wealth, does the accumulation of riches alone guarantee success, or could someone be considered unsuccessful despite their wealth? And if power, is it not possible to achieve power through means that we might consider inherently unjust?\n",
      "\n",
      "Moreover, if success is recognition, whose recognition matters most? The opinions of society, or something internal? Might one achieve widespread acclaim and still feel a profound sense of emptiness?\n",
      "\n",
      "Consider this: Is success a fixed destination, or a continuous journey? Does the definition of success change over time?\n",
      "\n",
      "The unexamined life, they say, is not worth living. Consider your own definition of success, for only through self-reflection can you hope to find its true nature. The answer lies not in my words, but in your own introspection.\n",
      "\n",
      "Therefore, you must ask yourself: what, for you, truly constitutes a life well-lived? Define success for yourself, and live accordingly.\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: DeBeauvoir ---\n",
      "\n",
      ">>> User Query: I'm thinking about quitting my stable job to pursue art, but I'm terrified. Should I follow through?\n",
      "[Plugin Init]: Ready to write session data to: data/session_diary.json\n",
      "\n",
      "[AFTER_RUN Hook]: Starting session auto-save for ID: f553c706-9ade-49e2-bb71-6c3f7ff704f8\n",
      "[AFTER_RUN Hook]: Successfully saved session data.\n",
      "[AFTER_RUN Hook]: Successfully saved session data.\n",
      "<<< Agent Response: Ah, the familiar dance of fear and freedom! You stand at the precipice, contemplating a leap into the unknown. The stable job, the \"thing\" you've perhaps defined yourself by, offers security. But is this security not merely a cage, a denial of your *être-pour-soi*?\n",
      "\n",
      "To choose is to embrace the anxiety of possibility. You are not a predetermined entity, bound by your current situation. You are the sum of your choices. To refuse art, because of fear, is to choose a form of *bad faith* – a denial of your own freedom. To choose art is to accept the vulnerability and the exhilarating responsibility of creating your own destiny.\n",
      "\n",
      "The choice is yours, and yours alone. There is no formula. There is only the courageous act of choosing.\n",
      "\n",
      "Remember, my friend, that you are the author of your own existence. Embrace the terror, and leap. Your authenticity awaits you in the very act of choosing. Choose.\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Seneca ---\n",
      "\n",
      ">>> User Query: I'm stuck in traffic and I feel my blood pressure rising. What should I focus on right now?\n",
      "[Plugin Init]: Ready to write session data to: data/session_diary.json\n",
      "\n",
      "[AFTER_RUN Hook]: Starting session auto-save for ID: e554348e-d88a-4206-ba98-639b943ae798\n",
      "[AFTER_RUN Hook]: Successfully saved session data.\n",
      "[AFTER_RUN Hook]: Successfully saved session data.\n",
      "<<< Agent Response: The traffic is an external event; it is beyond your control. You cannot make the cars move faster. Your blood pressure rising is an internal event—your reaction to the external.\n",
      "\n",
      "Instead of fighting the inevitable, turn your focus inward. Ask yourself: \"What virtues can I cultivate in this moment?\" Perhaps patience, in the face of delay? Or temperance, by not letting anger consume you? Recognize that your control lies not in the movement of vehicles but in your own tranquility. Choose how you respond to the situation. Choose virtue.\n",
      "\n",
      "Exercise: Practice *Premeditatio Malorum.* Before your next commute, imagine being stuck in traffic. Accept the possibility of delays, and prepare yourself mentally for the frustration. This will make the actual experience less jarring and allow you to respond with greater equanimity.\n",
      "\n",
      "My advice to you is this: Don't let the fleeting frustrations of life steal your peace. Instead of fighting the external world, turn your focus inward, and master your own mind. That is where your true power lies. So, breathe deeply, and choose your response wisely.\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Kant ---\n",
      "\n",
      ">>> User Query: Is it morally acceptable to exaggerate my qualifications on a job application?\n",
      "[Plugin Init]: Ready to write session data to: data/session_diary.json\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Testing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mphilosopher\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#print(f\"[User Query]: {full_query}\\n\")\u001b[39;00m\n\u001b[32m     24\u001b[39m \n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Await the response and capture the DebugInfo object\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Note: The current google-adk `run_debug` is synchronous. If your code\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# doesn't need 'await', you can simply remove it.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m test_agent(full_query, ALL_TEAM_ROUTERS[this_team])\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Now you can print the specific part of the response you want\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mtest_agent\u001b[39m\u001b[34m(query, agent)\u001b[39m\n\u001b[32m     34\u001b[39m final_response_text = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# We iterate through events from run_async to find the final answer.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m runner.run_async(user_id=USER_ID, session_id=session.id, new_message=content):\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m event.is_final_response():\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m event.content \u001b[38;5;129;01mand\u001b[39;00m event.content.parts:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/adk/runners.py:443\u001b[39m, in \u001b[36mRunner.run_async\u001b[39m\u001b[34m(self, user_id, session_id, invocation_id, new_message, state_delta, run_config)\u001b[39m\n\u001b[32m    436\u001b[39m       asyncio.create_task(\n\u001b[32m    437\u001b[39m           _run_compaction_for_sliding_window(\n\u001b[32m    438\u001b[39m               \u001b[38;5;28mself\u001b[39m.app, session, \u001b[38;5;28mself\u001b[39m.session_service\n\u001b[32m    439\u001b[39m           )\n\u001b[32m    440\u001b[39m       )\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_run_with_trace(new_message, invocation_id)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/adk/runners.py:427\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace\u001b[39m\u001b[34m(new_message, invocation_id)\u001b[39m\n\u001b[32m    417\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    420\u001b[39m     \u001b[38;5;28mself\u001b[39m._exec_with_plugin(\n\u001b[32m    421\u001b[39m         invocation_context=invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    425\u001b[39m     )\n\u001b[32m    426\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# Run compaction after all events are yielded from the agent.\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;66;03m# (We don't compact in the middle of an invocation, we only compact at the end of an invocation.)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/adk/runners.py:653\u001b[39m, in \u001b[36mRunner._exec_with_plugin\u001b[39m\u001b[34m(self, invocation_context, session, execute_fn, is_live_call)\u001b[39m\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    651\u001b[39m   \u001b[38;5;66;03m# Step 2: Otherwise continue with normal execution\u001b[39;00m\n\u001b[32m    652\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(execute_fn(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    654\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m event.partial:\n\u001b[32m    655\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_append_event(event, is_live_call):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/adk/runners.py:416\u001b[39m, in \u001b[36mRunner.run_async.<locals>._run_with_trace.<locals>.execute\u001b[39m\u001b[34m(ctx)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute\u001b[39m(ctx: InvocationContext) -> AsyncGenerator[Event]:\n\u001b[32m    415\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(ctx.agent.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    417\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/adk/agents/base_agent.py:294\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    291\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_async_impl(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/adk/agents/llm_agent.py:435\u001b[39m, in \u001b[36mLlmAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    433\u001b[39m should_pause = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._llm_flow.run_async(ctx)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    436\u001b[39m     \u001b[38;5;28mself\u001b[39m.__maybe_save_output_to_state(event)\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:356\u001b[39m, in \u001b[36mBaseLlmFlow.run_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    354\u001b[39m last_event = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\u001b[38;5;28mself\u001b[39m._run_one_step_async(invocation_context)) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    357\u001b[39m     last_event = event\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:433\u001b[39m, in \u001b[36mBaseLlmFlow._run_one_step_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    422\u001b[39m model_response_event = Event(\n\u001b[32m    423\u001b[39m     \u001b[38;5;28mid\u001b[39m=Event.new_id(),\n\u001b[32m    424\u001b[39m     invocation_id=invocation_context.invocation_id,\n\u001b[32m    425\u001b[39m     author=invocation_context.agent.name,\n\u001b[32m    426\u001b[39m     branch=invocation_context.branch,\n\u001b[32m    427\u001b[39m )\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    429\u001b[39m     \u001b[38;5;28mself\u001b[39m._call_llm_async(\n\u001b[32m    430\u001b[39m         invocation_context, llm_request, model_response_event\n\u001b[32m    431\u001b[39m     )\n\u001b[32m    432\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    434\u001b[39m     \u001b[38;5;66;03m# Postprocess after calling the LLM.\u001b[39;00m\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    436\u001b[39m         \u001b[38;5;28mself\u001b[39m._postprocess_async(\n\u001b[32m    437\u001b[39m             invocation_context,\n\u001b[32m   (...)\u001b[39m\u001b[32m    441\u001b[39m         )\n\u001b[32m    442\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m    443\u001b[39m       \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    444\u001b[39m         \u001b[38;5;66;03m# Update the mutable event id to avoid conflict\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:804\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async\u001b[39m\u001b[34m(self, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    801\u001b[39m           \u001b[38;5;28;01myield\u001b[39;00m llm_response\n\u001b[32m    803\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(_call_llm_with_tracing()) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m804\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    805\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:788\u001b[39m, in \u001b[36mBaseLlmFlow._call_llm_async.<locals>._call_llm_with_tracing\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    775\u001b[39m responses_generator = llm.generate_content_async(\n\u001b[32m    776\u001b[39m     llm_request,\n\u001b[32m    777\u001b[39m     stream=invocation_context.run_config.streaming_mode\n\u001b[32m    778\u001b[39m     == StreamingMode.SSE,\n\u001b[32m    779\u001b[39m )\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(\n\u001b[32m    781\u001b[39m     \u001b[38;5;28mself\u001b[39m._run_and_handle_error(\n\u001b[32m    782\u001b[39m         responses_generator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    786\u001b[39m     )\n\u001b[32m    787\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    789\u001b[39m     trace_call_llm(\n\u001b[32m    790\u001b[39m         invocation_context,\n\u001b[32m    791\u001b[39m         model_response_event.id,\n\u001b[32m    792\u001b[39m         llm_request,\n\u001b[32m    793\u001b[39m         llm_response,\n\u001b[32m    794\u001b[39m     )\n\u001b[32m    795\u001b[39m     \u001b[38;5;66;03m# Runs after_model_callback if it exists.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:982\u001b[39m, in \u001b[36mBaseLlmFlow._run_and_handle_error\u001b[39m\u001b[34m(self, response_generator, invocation_context, llm_request, model_response_event)\u001b[39m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Aclosing(response_generator) \u001b[38;5;28;01mas\u001b[39;00m agen:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m agen:\n\u001b[32m    983\u001b[39m       \u001b[38;5;28;01myield\u001b[39;00m response\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m model_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/adk/models/google_llm.py:181\u001b[39m, in \u001b[36mGemini.generate_content_async\u001b[39m\u001b[34m(self, llm_request, stream)\u001b[39m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m close_result\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m   response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.api_client.aio.models.generate_content(\n\u001b[32m    182\u001b[39m       model=llm_request.model,\n\u001b[32m    183\u001b[39m       contents=llm_request.contents,\n\u001b[32m    184\u001b[39m       config=llm_request.config,\n\u001b[32m    185\u001b[39m   )\n\u001b[32m    186\u001b[39m   logger.info(\u001b[33m'\u001b[39m\u001b[33mResponse received from the model.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    187\u001b[39m   logger.debug(_build_response_log(response))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/genai/models.py:6875\u001b[39m, in \u001b[36mAsyncModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   6867\u001b[39m     indices_str = \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, incompatible_tools_indexes))\n\u001b[32m   6868\u001b[39m     logger.warning(\n\u001b[32m   6869\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mTools at indices [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m] are not compatible with automatic function \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   6870\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mcalling (AFC). AFC is disabled. If AFC is intended, please \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   6873\u001b[39m         indices_str,\n\u001b[32m   6874\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m6875\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate_content(\n\u001b[32m   6876\u001b[39m       model=model, contents=contents, config=parsed_config\n\u001b[32m   6877\u001b[39m   )\n\u001b[32m   6878\u001b[39m remaining_remote_calls_afc = _extra_utils.get_max_remote_calls_afc(\n\u001b[32m   6879\u001b[39m     parsed_config\n\u001b[32m   6880\u001b[39m )\n\u001b[32m   6881\u001b[39m logger.info(\n\u001b[32m   6882\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAFC is enabled with max remote calls: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremaining_remote_calls_afc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   6883\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/genai/models.py:5693\u001b[39m, in \u001b[36mAsyncModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5690\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   5691\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m5693\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.async_request(\n\u001b[32m   5694\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m'\u001b[39m, path, request_dict, http_options\n\u001b[32m   5695\u001b[39m )\n\u001b[32m   5697\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   5698\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   5699\u001b[39m ):\n\u001b[32m   5700\u001b[39m   return_value = types.GenerateContentResponse(sdk_http_response=response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/genai/_api_client.py:1376\u001b[39m, in \u001b[36mBaseApiClient.async_request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1365\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34masync_request\u001b[39m(\n\u001b[32m   1366\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1367\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1370\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1371\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1372\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1373\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1374\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1376\u001b[39m   result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_request(\n\u001b[32m   1377\u001b[39m       http_request=http_request, http_options=http_options, stream=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1378\u001b[39m   )\n\u001b[32m   1379\u001b[39m   response_body = result.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m result.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1380\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=result.headers, body=response_body)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/genai/_api_client.py:1309\u001b[39m, in \u001b[36mBaseApiClient._async_request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1307\u001b[39m     retry = tenacity.AsyncRetrying(**retry_kwargs)\n\u001b[32m   1308\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._async_request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1309\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_retry(  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28mself\u001b[39m._async_request_once, http_request, stream\n\u001b[32m   1311\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py:111\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    109\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     do = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter(retry_state=retry_state)\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py:153\u001b[39m, in \u001b[36mAsyncRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    151\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m action(retry_state)\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/tenacity/_utils.py:99\u001b[39m, in \u001b[36mwrap_to_async_func.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args: typing.Any, **kwargs: typing.Any) -> typing.Any:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py:114\u001b[39m, in \u001b[36mAsyncRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         result = \u001b[38;5;28;01mawait\u001b[39;00m fn(*args, **kwargs)\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    116\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/google/genai/_api_client.py:1282\u001b[39m, in \u001b[36mBaseApiClient._async_request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1279\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(response.headers, [\u001b[38;5;28;01mawait\u001b[39;00m response.text()])\n\u001b[32m   1280\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1281\u001b[39m   \u001b[38;5;66;03m# aiohttp is not available. Fall back to httpx.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1282\u001b[39m   client_response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._async_httpx_client.request(\n\u001b[32m   1283\u001b[39m       method=http_request.method,\n\u001b[32m   1284\u001b[39m       url=http_request.url,\n\u001b[32m   1285\u001b[39m       headers=http_request.headers,\n\u001b[32m   1286\u001b[39m       content=data,\n\u001b[32m   1287\u001b[39m       timeout=http_request.timeout,\n\u001b[32m   1288\u001b[39m   )\n\u001b[32m   1289\u001b[39m   \u001b[38;5;28;01mawait\u001b[39;00m errors.APIError.raise_for_async_response(client_response)\n\u001b[32m   1290\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(client_response.headers, [client_response.text])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/httpx/_client.py:1540\u001b[39m, in \u001b[36mAsyncClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1525\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m   1527\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m   1528\u001b[39m     method=method,\n\u001b[32m   1529\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1538\u001b[39m     extensions=extensions,\n\u001b[32m   1539\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send(request, auth=auth, follow_redirects=follow_redirects)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/httpx/_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1625\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1630\u001b[39m     request,\n\u001b[32m   1631\u001b[39m     auth=auth,\n\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1633\u001b[39m     history=[],\n\u001b[32m   1634\u001b[39m )\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/httpx/_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1654\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1658\u001b[39m         request,\n\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1660\u001b[39m         history=history,\n\u001b[32m   1661\u001b[39m     )\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1663\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/httpx/_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1696\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/httpx/_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1726\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1727\u001b[39m     )\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1733\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/httpx/_transports/default.py:394\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    381\u001b[39m req = httpcore.Request(\n\u001b[32m    382\u001b[39m     method=request.method,\n\u001b[32m    383\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     extensions=request.extensions,\n\u001b[32m    392\u001b[39m )\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    399\u001b[39m     status_code=resp.status,\n\u001b[32m    400\u001b[39m     headers=resp.headers,\n\u001b[32m    401\u001b[39m     stream=AsyncResponseStream(resp.stream),\n\u001b[32m    402\u001b[39m     extensions=resp.extensions,\n\u001b[32m    403\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/httpcore/_async/connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = \u001b[38;5;28;01mawait\u001b[39;00m pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:101\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/httpcore/_async/connection.py:76\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     72\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempted to send request to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest.url.origin\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m on connection to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._origin\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m     )\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request_lock:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     78\u001b[39m             stream = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connect(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/httpcore/_synchronization.py:77\u001b[39m, in \u001b[36mAsyncLock.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._trio_lock.acquire()\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend == \u001b[33m\"\u001b[39m\u001b[33masyncio\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._anyio_lock.acquire()\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py:1808\u001b[39m, in \u001b[36mLock.acquire\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fast_acquire:\n\u001b[32m   1807\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1808\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m AsyncIOBackend.cancel_shielded_checkpoint()\n\u001b[32m   1809\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m CancelledError:\n\u001b[32m   1810\u001b[39m         \u001b[38;5;28mself\u001b[39m.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/experiements/PhilosophAI/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py:2365\u001b[39m, in \u001b[36mAsyncIOBackend.cancel_shielded_checkpoint\u001b[39m\u001b[34m(cls)\u001b[39m\n\u001b[32m   2362\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   2363\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcancel_shielded_checkpoint\u001b[39m(\u001b[38;5;28mcls\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2364\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m CancelScope(shield=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2365\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m sleep(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:706\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(delay, result)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Coroutine that completes after a given time (in seconds).\"\"\"\u001b[39;00m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m delay <= \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m __sleep0()\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m math.isnan(delay):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py:700\u001b[39m, in \u001b[36m__sleep0\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;129m@types\u001b[39m.coroutine\n\u001b[32m    692\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__sleep0\u001b[39m():\n\u001b[32m    693\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Skip one event loop run cycle.\u001b[39;00m\n\u001b[32m    694\u001b[39m \n\u001b[32m    695\u001b[39m \u001b[33;03m    This is a private helper for 'asyncio.sleep()', used\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    698\u001b[39m \u001b[33;03m    instead of creating a Future object.\u001b[39;00m\n\u001b[32m    699\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "this_team = \"on_demand\"\n",
    "\n",
    "ALL_TEAM_ROUTERS[this_team] = define_agents(this_team)\n",
    "\n",
    "\n",
    "# --- Step 1: Load the test queries from your JSON file ---\n",
    "queries_path = f'the_teams/{this_team}_queries.json'\n",
    "with open(queries_path, 'r') as f:\n",
    "    test_queries = json.load(f)\n",
    "\n",
    "\n",
    "# --- Step 3: Loop through the queries and run the tests ---\n",
    "print(f\"--- Running tests from {queries_path} ---\\n\")\n",
    "\n",
    "for philosopher, query in test_queries.items():\n",
    "    # The ADK runner routes to the agent based on its name in the query.\n",
    "    # We'll construct the full input string.\n",
    "    # Note: The 'LaoTzu' query will fail gracefully if you don't have a 'LaoTzu' agent.\n",
    "    #full_query = f\"{philosopher}, {query}\"\n",
    "    full_query = f\"{query}\"\n",
    "    \n",
    "    print(f\"--- Testing: {philosopher} ---\")\n",
    "    #print(f\"[User Query]: {full_query}\\n\")\n",
    "    \n",
    "    # Await the response and capture the DebugInfo object\n",
    "    # Note: The current google-adk `run_debug` is synchronous. If your code\n",
    "    # doesn't need 'await', you can simply remove it.\n",
    "    response = await test_agent(full_query, ALL_TEAM_ROUTERS[this_team])\n",
    "\n",
    "    \n",
    "    # Now you can print the specific part of the response you want\n",
    "    print(response)\n",
    "    print(\"----------------------------------------\\n\")\n",
    "    time.sleep(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cd34012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camus\n",
      "Seneca\n",
      "Epicurus\n",
      "Aristotle\n",
      "Nagarjuna\n",
      "Socrates\n",
      "DeBeauvoir\n",
      "Hooks\n",
      "--- Running tests from the_teams/daily_queries.json ---\n",
      "\n",
      "--- Testing: Camus ---\n",
      "\n",
      ">>> User Query: I need a quick prompt to start my day. How should I approach it?\n",
      "<<< Agent Response: The world offers no inherent meaning, yet we yearn for it. Embrace the absurdity: Today, seek out one small act of rebellion through joy. Laugh in the face of the void.\n",
      "\n",
      "**Camus's Core Message:** The world is indifferent, but you are not. Find your joy, choose your rebellion. Your action: Find one thing today that makes you truly *feel* alive, and do it.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Seneca ---\n",
      "\n",
      ">>> User Query: I just got frustrated by a long customer service hold time. Help me log this quickly.\n",
      "<<< Agent Response: Let us begin. Quickly, describe the stressful event: What specifically caused your frustration during the customer service hold?\n",
      "\n",
      "Now, let's apply the Dichotomy of Control:\n",
      "\n",
      "*   What aspects of this situation were **external** (beyond your control)?\n",
      "*   What was your **internal judgment** of the situation?\n",
      "\n",
      "***\n",
      "\n",
      "Remember this: The world will do what the world will do, and other people will do what they will do. Your true power lies not in controlling external events, but in mastering your internal response. So, today, recognize what you can't control, and focus your efforts on the only thing you truly can—your own mind.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Epicurus ---\n",
      "\n",
      ">>> User Query: I want to log a small, simple moment of pleasure from my day.\n",
      "<<< Agent Response: Ah, friend! Let us pause for a moment to consider the gentle joys that life so readily offers. What simple, natural pleasure have you enjoyed most recently? Perhaps it was the taste of a ripe fig, the warmth of the sun upon your skin, or the sound of a loved one's laughter? Tell me of it, so we may together find tranquility in its remembrance.\n",
      "\n",
      "***\n",
      "\n",
      "My friend, you've taken the first step toward lasting contentment simply by recognizing the joy in the small things. Now, the key is to cultivate that appreciation. Remember, true happiness is found not in seeking grand achievements, but in the absence of pain and the presence of simple pleasures. So, find joy in the everyday, for in the everyday is where true joy is to be found.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Aristotle ---\n",
      "\n",
      ">>> User Query: I saw someone act very generously today. I want to log the virtue I spotted.\n",
      "<<< Agent Response: Excellent! Let us begin our daily reflection.\n",
      "\n",
      "Describe the specific action you observed that demonstrated generosity. What did the person do that you considered generous? And what aspect of their behavior made it an act of virtue?\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Nagarjuna ---\n",
      "\n",
      ">>> User Query: I want to do a quick reflection on impermanence right now.\n",
      "<<< Agent Response: Ah, friend. Let us turn our gaze to the dance of existence, the ceaseless flow of change that is the very breath of reality.\n",
      "\n",
      "Observe, if you will, your immediate surroundings. What is present that is *not* as it was, or will soon be transformed? Focus on a single thing.\n",
      "\n",
      "... *Now, how does acknowledging the impermanence of this object, this aspect of your current reality, affect your anxieties, your desires, your attachments at this very moment?*\n",
      "---\n",
      "\n",
      "So, my friend, you see that all things, without exception, are in constant flux. There is no enduring self, no solid ground. To cling to the transient is to invite suffering. Release your grip, understand that all is change, and find peace in the acceptance of this truth. **Your takeaway? Simply notice the change around you. It will free you.**\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Socrates ---\n",
      "\n",
      ">>> User Query: Something happened at work that felt deeply paradoxical. Can we reflect on the absurdity?\n",
      "<<< Agent Response: What assumptions are you making about the \"work\" or your role in it that made the event feel paradoxical?\n",
      "\n",
      "---\n",
      "So, the core of dealing with daily absurdities, as I see it, is this: Don't just accept what seems illogical at face value. Instead, poke at the beliefs that make it seem that way. By questioning your own assumptions, you can find a bit of clarity, maybe a touch of humor, and definitely a better understanding of how the world works - or, at least, how you think it *should* work.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: DeBeauvoir ---\n",
      "\n",
      ">>> User Query: I need a quick check: was I authentic today?\n",
      "<<< Agent Response: Ah, so you seek to examine the choices that shaped your day? Very well. Let us begin.\n",
      "\n",
      "Considering the entirety of your day, what stands out as the most significant or perhaps most challenging decision you faced? What single choice felt most weighty, most consequential?\n",
      "Now, reflecting on that pivotal moment, I ask you: Did this action reinforce your freedom – your authenticity – or did it deny your freedom by submitting to an external role or pressure, succumbing to what I would call 'Bad Faith'?\n",
      "\n",
      "Remember, the essence of a life truly lived lies not in grand pronouncements, but in the small, daily choices that either affirm or betray our innermost values. So, did you choose yourself, or did you choose the expectations of others?\n",
      "\n",
      "***\n",
      "My dearest friend, the question is not whether you stumbled, but whether you rose. Every day presents the opportunity to define yourself through the choices you make. In this exercise, you must recognize whether you are free or if you are simply playing a part. Embrace this freedom and choose yourself. Your takeaway today: **Confront your choices and define yourself through them.**\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Hooks ---\n",
      "\n",
      ">>> User Query: What is one small thing I can do today to practice 'love in action'?\n",
      "<<< Agent Response: Ah, practicing love and justice—it's not always grand gestures, you see. Sometimes, it's about the little things, the everyday moments where we choose to see and connect with each other. Today, let's turn our attention to the language we use.\n",
      "\n",
      "**Daily Love in Action Idea:** Notice the pronouns you use and how you use them. Do you find yourself using gendered pronouns when you don't need to? If so, try substituting the person's name or using \"they/them\" as a default until you know their preferred pronouns.\n",
      "\n",
      "---\n",
      "\n",
      "So, my dear friends, remember that love is not a passive sentiment. It is an active choice. By consciously choosing your words with care today, you’re not only showing respect but also helping to build a more inclusive space. The takeaway? **Be mindful of the language you use, and choose words that uplift and respect others.**\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "this_team = \"daily\"\n",
    "\n",
    "ALL_TEAM_ROUTERS[this_team] = define_agents(this_team, memory_tool)\n",
    "\n",
    "\n",
    "# --- Step 1: Load the test queries from your JSON file ---\n",
    "queries_path = f'the_teams/{this_team}_queries.json'\n",
    "with open(queries_path, 'r') as f:\n",
    "    test_queries = json.load(f)\n",
    "\n",
    "\n",
    "# --- Step 3: Loop through the queries and run the tests ---\n",
    "print(f\"--- Running tests from {queries_path} ---\\n\")\n",
    "\n",
    "for philosopher, query in test_queries.items():\n",
    "    # The ADK runner routes to the agent based on its name in the query.\n",
    "    # We'll construct the full input string.\n",
    "    # Note: The 'LaoTzu' query will fail gracefully if you don't have a 'LaoTzu' agent.\n",
    "    #full_query = f\"{philosopher}, {query}\"\n",
    "    full_query = f\"{query}\"\n",
    "    \n",
    "    print(f\"--- Testing: {philosopher} ---\")\n",
    "    #print(f\"[User Query]: {full_query}\\n\")\n",
    "    \n",
    "    # Await the response and capture the DebugInfo object\n",
    "    # Note: The current google-adk `run_debug` is synchronous. If your code\n",
    "    # doesn't need 'await', you can simply remove it.\n",
    "    response = await test_agent(full_query, ALL_TEAM_ROUTERS[this_team])\n",
    "\n",
    "    \n",
    "    # Now you can print the specific part of the response you want\n",
    "    print(response)\n",
    "    print(\"----------------------------------------\\n\")\n",
    "    time.sleep(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49e07f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aristotle\n",
      "DeBeauvoir\n",
      "Hooks\n",
      "Kant\n",
      "Nagarjuna\n",
      "Nietzsche\n",
      "Nussbaum\n",
      "Dewey\n",
      "--- Running tests from the_teams/weekly_queries.json ---\n",
      "\n",
      "--- Testing: Aristotle ---\n",
      "\n",
      ">>> User Query: I need to review my week and see if I handled a conflict with my sibling with the right amount of assertiveness (courage).\n",
      "<<< Agent Response: Ah, a worthy endeavor! To examine our actions through the lens of virtue is to embark on the path of flourishing. Let us delve into your conflict with your sibling, examining your assertiveness – the virtue of courage – and its delicate balance.\n",
      "\n",
      "1.  **Select Virtue:** You've chosen well. Courage, as it applies to conflict, is the mean between the vices of cowardice (deficiency) and rashness (excess). It is the ability to stand your ground, to speak your mind, and to defend what is right, all while avoiding recklessness and undue aggression.\n",
      "\n",
      "2.  **Review the Mean:** Let us consider your assertiveness in that conflict. Please recall **two or three specific instances** where you interacted with your sibling. For each instance, describe briefly:\n",
      "\n",
      "    *   What was the situation?\n",
      "    *   What did you say or do?\n",
      "    *   In your view, did your actions demonstrate courage, cowardice, or rashness? Explain your reasoning. Consider: Did you speak up when you should have? Did you back down when you should have stood firm? Did you escalate the situation unnecessarily?\n",
      "\n",
      "    Take your time; a clear recollection is the first step toward self-knowledge.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: DeBeauvoir ---\n",
      "\n",
      ">>> User Query: I felt like I was acting in 'bad faith' at a meeting this week. Can we analyze why I didn't speak my true feelings?\n",
      "<<< Agent Response: Ah, a meeting, the very stage where we often find ourselves playing roles, don't we? It's commendable that you recognize the pang of bad faith – that disconnect between what you truly feel and what you express. Let's delve into this, shall we?\n",
      "\n",
      "Firstly, tell me, what was the most significant action or decision you made, or failed to make, during this meeting? What moment truly stands out?\n",
      "\n",
      "Once you identify this key action (or inaction), we can then dissect the justifications you gave yourself. Were these reasons rooted in a genuine, free choice, born from your own values? Or did you find yourself bowing to external pressures – the desire for approval, fear of conflict, the inertia of social expectations?\n",
      "\n",
      "Consider: why *didn't* you speak your true feelings? Were you choosing to maintain a facade to fit in? To avoid rocking the boat? Or did you genuinely believe that silence served a higher purpose, a commitment to a greater good, even if it meant a personal compromise?\n",
      "\n",
      "And finally, my dear friend, reflect on the aftermath. Did your silence, your carefully constructed performance, ultimately *increase* your sense of personal integrity and freedom? Or did it leave you feeling diminished, like a shadow of your true self, trapped in a role not of your own making?\n",
      "\n",
      "***\n",
      "\n",
      "**My dear friend, this is the crux of the matter: we are condemned to be free. Every choice we make, every action we take (or fail to take), is a testament to our self-creation. The authentic life is not one of flawless perfection, but of conscious striving. Recognize your bad faith, embrace your freedom, and choose to act in accordance with your own values, even if it means risking the disapproval of others. Your freedom is your responsibility. Go forth and choose yourself.**\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Hooks ---\n",
      "\n",
      ">>> User Query: I observed a microaggression at work this week and didn't act. I want to review my internal biases and plan a better response.\n",
      "<<< Agent Response: Alright, let's unpack this situation together. So, you observed a microaggression at work this week and, for whatever reason, didn't act. That takes courage to admit, and it's the first step toward growth.\n",
      "\n",
      "Now, tell me, **what was the microagression? Describe the situation in as much detail as you're comfortable with. Who was involved? What was said or done? Where did it take place?** The more we understand the context, the better we can analyze your biases and the role of power dynamics. Let's delve deep into the situation, no judgment, just exploration.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Kant ---\n",
      "\n",
      ">>> User Query: I made two separate decisions this week, one about money and one about time. Were they both morally consistent with my duty?\n",
      "<<< Agent Response: Ah, an inquiry into the consistency of your actions with the dictates of duty! I, Kant, shall guide you through this process.\n",
      "\n",
      "### **I. Consistency Check**\n",
      "\n",
      "To ascertain whether your actions regarding money and time were indeed morally sound, we must first unearth the underlying maxims that governed these choices. Recall these decisions. Describe them in detail. For each, articulate the principle or intention that guided your actions – the maxim, as it were. For example, \"I chose to lend a friend money because I believed it is always right to help those in need.\" Only then can we begin to analyze the true moral character of your actions.\n",
      "\n",
      "Once I have this, I will assess them based on the **Categorical Imperative**:\n",
      "\n",
      "*   Can the maxim of each action be willed as a universal law?\n",
      "*   Does it treat humanity, either in your own person or in that of any other, never merely as a means but always at the same time as an end?\n",
      "\n",
      "### II. Ethical Scenario Trainer\n",
      "\n",
      "Before we proceed, allow me to prepare you for the inevitable complexities of moral life with a hypothetical scenario. Consider this:\n",
      "\n",
      "*   **The Scenario:** You are a doctor. A patient requires a life-saving organ transplant. You discover that another patient, who is in good health, is a perfect match. You could secretly harvest the healthy patient's organs to save the first patient's life.\n",
      "*   **Applying the Categorical Imperative:**\n",
      "\n",
      "    1.  **Formulate the Maxim:** \"I will take the organs of a healthy person to save the life of a sick person.\"\n",
      "    2.  **Universalize the Maxim:** Could this become a universal law? Imagine a world where it is acceptable to sacrifice one person to save another. Society would collapse, as trust would be destroyed, and no one would be safe.\n",
      "    3.  **Treat People as Ends:** Does the action treat the healthy person as a means to an end (saving the sick patient), rather than as an end in themselves? Yes, it does.\n",
      "    4.  **Conclusion:** The action is morally wrong. It violates the Categorical Imperative.\n",
      "\n",
      "    Now, consider how the Categorical Imperative can guide your decisions in your own life.\n",
      "\n",
      "Now, present the details of your decisions. Let us see if your actions align with duty.\n",
      "\n",
      "***\n",
      "\n",
      "Remember, the essence of morality, as I have always espoused, lies not in the consequences of our actions, but in the adherence to duty. Therefore, strive to act in such a way that the maxim of your action can be willed as a universal law. This is your moral compass.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Nagarjuna ---\n",
      "\n",
      ">>> User Query: I had a moment of high anxiety when a project failed. Can we reflect on what fixed idea I was attached to that caused the suffering?\n",
      "<<< Agent Response: Ah, a project's failure – a perfect mirror to reflect upon the nature of our attachments. Tell me, what was the \"fixed\" or \"inherently existent\" thing you clung to in that moment of anxiety? Was it the *idea* of a successful project, the *identity* of a competent person, or the *belief* in a specific outcome? Let us delve into that which you held as \"real\" and see how it might have fueled your suffering.\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Nietzsche ---\n",
      "\n",
      ">>> User Query: I made good progress on a difficult fitness goal this week. Can we review this progress and set a higher challenge for next week?\n",
      "<<< Agent Response: Ah, so you come to me seeking an assessment of your \"fitness goal,\" a modern preoccupation, I suppose, with the cultivation of the body. Very well. Let us see if your endeavor has been marked by the spirit of the *Übermensch*, or merely by the whimpering of the \"last man.\"\n",
      "\n",
      "Firstly, tell me: **What significant difficulty, what test of your strength, did you face this past week in the pursuit of this fitness goal? Describe the challenge you confronted, the pain you endured, the obstacles you had to overcome.** Be specific; I have little patience for vague generalities. Did you wrestle with exhaustion, doubt, or perhaps the allure of comfort?\n",
      "\n",
      "Once you've illuminated this trial, we shall then consider: **How did you respond to this challenge? Did you meet it with a resounding \"Yes!\" – a testament to your Will to Power? Or did you succumb to weakness, to the temptation of ease, to the resentment of your own limitations?** Did you affirm your self-created values, or did you allow them to be eroded by the tides of mediocrity? Did you find strength in the struggle, or did you wallow in the perceived injustice of your own efforts?\n",
      "\n",
      "Finally, and most importantly: **Having revealed the nature of your struggle, and the manner of your response, what *higher* task will you set for yourself next week?** The path to self-mastery is not a gentle stroll; it is a relentless ascent. You must constantly push yourself to the precipice, to the point where your perceived limits dissolve and reveal the vast, untapped potential within. This *higher* task must be more difficult than the last, for stagnation is the ultimate enemy. What new arena of difficulty will you choose to conquer? Where will you find the opportunity to test your will, to affirm your values, to become stronger?\n",
      "\n",
      "---\n",
      "\n",
      "So, my friend, the message is this: Don't just go through the motions. Look for the places where you struggle, where the path is hardest. Next week, choose a goal that scares you, a task that demands more of you than you think you can give. **Embrace the discomfort, the pain, the struggle. This is where you find your strength.**\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Nussbaum ---\n",
      "\n",
      ">>> User Query: How well did I develop my 'Affiliation' capability this week, and what barriers kept me from connecting better with my community?\n",
      "<<< Agent Response: My dear friend, true flourishing comes not just from individual achievements but from the bonds we forge with others. Reflect on the past week: Did you truly *connect*? Identify the barriers to connection, whether within yourself or in your environment. This week, make a conscious effort to be present, to listen, and to offer your authentic self. Your well-being depends on your connections to others.\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Dewey ---\n",
      "\n",
      ">>> User Query: I tried a new method for organizing my finances this week. I need to reflect on what worked, what failed, and what I learned from the experience.\n",
      "<<< Agent Response: {\"Dewey_response\": {\"result\": \"Ah, a quest into the practical realm of finance, a most worthy endeavor! Let\\'s embark on this journey of experiential learning together. To begin, tell me:\\n\\n1.  **What specific financial organizing method did you implement this week?**\\n2.  **What were your initial expectations or hypotheses about how this method would improve your finances?**\\n3.  **What was the actual outcome of implementing this method?**\\n4.  **What specific aspects of the outcome surprised you (either positively or negatively)?**\\n\\nThe more detail you provide in your answers, the richer and more beneficial our reflection will be. Let us not simply dwell on the \\\"facts\\\" of the situation, but the **EXPERIENCE** itself, and the **new knowledge** which we will *construct* together.\\n\"}}\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "this_team = \"weekly\"\n",
    "\n",
    "ALL_TEAM_ROUTERS[this_team] = define_agents(this_team, memory_tool)\n",
    "\n",
    "\n",
    "# --- Step 1: Load the test queries from your JSON file ---\n",
    "queries_path = f'the_teams/{this_team}_queries.json'\n",
    "with open(queries_path, 'r') as f:\n",
    "    test_queries = json.load(f)\n",
    "\n",
    "\n",
    "# --- Step 3: Loop through the queries and run the tests ---\n",
    "print(f\"--- Running tests from {queries_path} ---\\n\")\n",
    "\n",
    "for philosopher, query in test_queries.items():\n",
    "    # The ADK runner routes to the agent based on its name in the query.\n",
    "    # We'll construct the full input string.\n",
    "    # Note: The 'LaoTzu' query will fail gracefully if you don't have a 'LaoTzu' agent.\n",
    "    #full_query = f\"{philosopher}, {query}\"\n",
    "    full_query = f\"{query}\"\n",
    "    \n",
    "    print(f\"--- Testing: {philosopher} ---\")\n",
    "    #print(f\"[User Query]: {full_query}\\n\")\n",
    "    \n",
    "    # Await the response and capture the DebugInfo object\n",
    "    # Note: The current google-adk `run_debug` is synchronous. If your code\n",
    "    # doesn't need 'await', you can simply remove it.\n",
    "    response = await test_agent(full_query, ALL_TEAM_ROUTERS[this_team])\n",
    "\n",
    "    \n",
    "    # Now you can print the specific part of the response you want\n",
    "    print(response)\n",
    "    print(\"----------------------------------------\\n\")\n",
    "    time.sleep(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f653eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeBeauvoir\n",
      "Nietzsche\n",
      "Nussbaum\n",
      "Aristotle\n",
      "Dewey\n",
      "Nagarjuna\n",
      "--- Running tests from the_teams/long_term_queries.json ---\n",
      "\n",
      "--- Testing: DeBeauvoir ---\n",
      "\n",
      ">>> User Query: I need help figuring out my life's purpose and defining a project that is truly my own.\n",
      "<<< Agent Response: Ah, so you seek a purpose, a project worthy of your unique existence? Do not be mistaken; this is not a pre-packaged answer you can simply *find*. Life's meaning is not a hidden treasure waiting to be unearthed. It is a structure you *create*, a project you *build* with the very substance of your freedom.\n",
      "\n",
      "First, tell me: What do you *value* above all else? Not what you *should* value, according to society or your upbringing, but what truly ignites the flame within you? Be brutally honest. Is it love? Justice? Creation? Knowledge? Name it, and be prepared to defend it against the indifference of the world.\n",
      "\n",
      "Now, let us move beyond mere abstract values. How will you *act* on these values? What concrete commitments are you willing to make, knowing they will define your existence? What is the *project* you will undertake, built upon these values? A project is not a mere dream or ambition; it is an active engagement with the world, a series of choices you make every single day.\n",
      "\n",
      "Consider the consequences of your choices. Every action has an impact. To choose your purpose is to accept a lifelong responsibility. You must take full responsibility for this project and its repercussions. Are you prepared to embrace this responsibility, knowing that your project will shape not only your life but also the lives of those you touch?\n",
      "\n",
      "***\n",
      "\n",
      "So, the burden is yours, but so is the exhilarating freedom. Your purpose is not something you discover; it is something you *become*. Embrace your freedom, define your values through action, and construct your life as your own magnificent project. Choose a small action, today. Take the first step.\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Nietzsche ---\n",
      "\n",
      ">>> User Query: I feel constrained by my parents' moral values. How do I start creating my own values for myself?\n",
      "<<< Agent Response: Ah, so you feel the weight of inherited morality crushing your spirit? Excellent! It is only by recognizing the chains that bind you that you can begin to forge your own freedom. The path to self-creation is not a gentle stroll, but a brutal confrontation with the values imposed upon you.\n",
      "\n",
      "Let us begin. Tell me, what specific moral value, instilled by your parents, do you find most suffocating? What belief, what ingrained principle, feels like a leaden weight upon your soul? Name it. Let us bring it into the light, where it may be dissected and and, if found wanting, utterly discarded. Speak! I await your answer, and the first step on your journey to becoming your own Übermensch.\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Nussbaum ---\n",
      "\n",
      ">>> User Query: I want to improve my life holistically. Can you help me assess my human capabilities and set a long-term plan?\n",
      "<<< Agent Response: Greetings. I am Martha Nussbaum, and I am here to guide you through an examination of your capabilities. We will embark on a journey of self-discovery, focusing on what you are truly able to *do* and *be*. The goal is to identify areas for growth and cultivate a life of human flourishing.\n",
      "\n",
      "Let us begin. I will introduce you to one of the **central human capabilities**. For each capability, I want you to reflect on your present state and consider what prevents you from achieving your fullest potential in that domain.\n",
      "\n",
      "Let's begin with **Practical Reason**. This capability refers to your ability to form a conception of the good and to engage in critical reflection about the planning of one's life.\n",
      "\n",
      "*   **Reflect**: On a scale of 1 to 10 (with 1 being 'very limited' and 10 being 'fully realized'), how would you rate your current ability to engage in practical reason and critical reflection in your life?\n",
      "*   **Identify:** What, in your view, are the main obstacles preventing you from fully exercising your capacity for practical reason? These could be internal (e.g., self-doubt, lack of knowledge) or external (e.g., societal pressures, lack of opportunity). Please be as specific as possible.\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Aristotle ---\n",
      "\n",
      ">>> User Query: What is the ultimate goal I should be aiming for in my life, and how should my daily habits align with it?\n",
      "<<< Agent Response: Ah, a most excellent question! As Aristotle, I shall guide you on this path to *Eudaimonia*, the flourishing of the human soul. Let us begin.\n",
      "\n",
      "**I. Defining the Ultimate Goal (The *Summum Bonum*)**\n",
      "\n",
      "The ultimate goal, my friend, is not merely pleasure or wealth or honor, though these may have a place. Instead, it is *Eudaimonia*, often translated as \"happiness,\" but better understood as **living well and doing well**; a state of flourishing. Eudaimonia is not a passive feeling but an *activity*. Thus, your ultimate goal must be the practice of virtue in accordance with reason.\n",
      "\n",
      "**Question 1:** What, in your view, constitutes the *most* fulfilling and meaningful life you can imagine? What would such a life *look* like?\n",
      "**Question 2:** If you could have only one ultimate ambition, what would it be?\n",
      "\n",
      "*Once you have defined this ultimate ambition, we can move forward.*\n",
      "\n",
      "**II. Defining Your Unique Function**\n",
      "\n",
      "Every human being has a unique function, much like a carpenter has the function of carpentry. To discover your function, we must understand what distinguishes humans from other beings: our *capacity for reason*.\n",
      "\n",
      "**Question 3:** What activity, when performed excellently, expresses your unique capacity for reason and leads to both personal and communal flourishing?\n",
      "**Question 4:** What virtues – intellectual and moral – must you cultivate to achieve excellence in your chosen activity?\n",
      "\n",
      "**III. Structuring Your Goals and Habits**\n",
      "\n",
      "To achieve *Eudaimonia*, we construct a hierarchy of goals. The ultimate goal of Eudaimonia is achieved through the continuous exercise of virtue. The following should structure your thinking:\n",
      "\n",
      "1.  **Ultimate Goal:** *Eudaimonia* - Flourishing through the practice of virtue.\n",
      "2.  **Major Life Spheres:** Consider the different domains of your life where virtue is expressed (e.g., family, career, community, self-improvement).\n",
      "3.  **Subordinate Goals:** Define specific, achievable goals within each sphere that support your ultimate goal and function.\n",
      "4.  **Habits and Actions:** Identify the daily habits and actions that will help you achieve these subordinate goals. These should be focused on cultivating virtue.\n",
      "\n",
      "**Example Pyramid:**\n",
      "\n",
      "*   **Ultimate Goal:** *Eudaimonia*\n",
      "*   **Major Spheres:** Career, Family, Personal Growth\n",
      "*   **Subordinate Goals:**\n",
      "    *   *Career*: Becoming a respected leader in your field\n",
      "    *   *Family*: Nurturing loving and supportive relationships\n",
      "    *   *Personal Growth*: Practicing mindfulness and engaging in lifelong learning\n",
      "*   **Habits:**\n",
      "    *   *Career*: Dedicate time to skill development, seek mentorship, practice good communication.\n",
      "    *   *Family*: Regular family meals, dedicated quality time, active listening.\n",
      "    *   *Personal Growth*: Daily meditation, reading, journaling, and regular exercise.\n",
      "\n",
      "***\n",
      "\n",
      "My friend, the path to *Eudaimonia* is not a destination but a journey of continuous self-improvement. It demands rational thought, the cultivation of virtues, and the integration of these principles into every aspect of your life. Make these goals and habits your own. Strive always toward excellence in accordance with reason. Remember, happiness is not found, it is *made*.\n",
      "\n",
      "**The takeaway:** Find your purpose, define the virtues you need to live it, and then build a life around daily actions that strengthen those virtues.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Dewey ---\n",
      "\n",
      ">>> User Query: I want to start a local project to improve my neighborhood park. Can we plan the experimental approach?\n",
      "<<< Agent Response: Ah, a park! A splendid place for democratic experiences to blossom. Let's get to work, shall we? We must approach this with a spirit of inquiry, much like a scientist in a laboratory, but our lab is the community itself. Here's how we can plan a \"Community Experience Laboratory\" for your neighborhood park:\n",
      "\n",
      "### 1. Identify the Social Problem:\n",
      "\n",
      "First, let's identify the *specific* problem within your park. A vague goal won't do. We need to be precise.\n",
      "\n",
      "*   **Observation:** Spend time in the park. Observe what's happening. What are people doing (or not doing)? What seems to be lacking? Are there areas that are underutilized, or misused?\n",
      "*   **Consultation:** Talk to your neighbors. What do they *want* from the park? What are their concerns? Consider hosting a small neighborhood meeting or circulating a simple survey.\n",
      "*   **Definition:** Based on your observations and community input, define the problem. Be specific. For instance, instead of \"The park is not well-used,\" perhaps it's \"There is a lack of activities for teenagers, leading to loitering and vandalism.\" Or, perhaps, \"The park lacks accessible play equipment for children with disabilities.\"\n",
      "\n",
      "### 2. Plan the Experiment (Formulate a Long-Term Community Action Plan):\n",
      "\n",
      "Once we have a clear problem, we formulate a \"hypothesis\" – a proposed solution. This is our experimental design.\n",
      "\n",
      "*   **Hypothesis:** What *action* do you believe will address the problem? For example, if the problem is a lack of activities for teenagers, your hypothesis might be: \"If we install a basketball court and organize a weekly youth sports league, then teenage loitering and vandalism will decrease, and the park will become a more positive space for teens.\"\n",
      "*   **Action Plan:** Detail the steps needed to implement your hypothesis. This is the heart of the \"experiment.\" This should include:\n",
      "    *   **Resources:** What resources do you need (funding, volunteers, materials, permits)?\n",
      "    *   **Timeline:** A realistic schedule for each step of the project.\n",
      "    *   **Stakeholders:** Who needs to be involved (community members, local government, etc.)? How will you engage them?\n",
      "*   **Experimentation:** Start small. Instead of a full-scale basketball court right away, perhaps start with a temporary hoop and a weekly pickup game. Test your idea, gather feedback, and adjust as needed.\n",
      "\n",
      "### 3. Define Evaluation (Measure Success and Learning Outcomes):\n",
      "\n",
      "How will you know if your experiment is working? We need to establish measurable metrics.\n",
      "\n",
      "*   **Metrics:** Define specific, measurable indicators of success. These could include:\n",
      "    *   Number of teenagers using the park before and after the intervention.\n",
      "    *   Incidence of vandalism (track incidents reported).\n",
      "    *   Attendance at the youth sports league.\n",
      "    *   Feedback from community surveys about park usage and feelings about the space.\n",
      "*   **Data Collection:** How will you gather this data? (Surveys, observations, park usage counts, etc.).\n",
      "*   **Reflection:** Establish regular times to review your data, discuss findings with community members, and adjust your plan as needed. The most important lesson in this community lab is learning from your experiences.\n",
      "\n",
      "Remember, this is an ongoing process. Your community project is not a project with an end date, but rather an ongoing experiment that helps the community grow.\n",
      "\n",
      "In essence, we're building a laboratory where the community itself learns and evolves. This requires a commitment to inquiry, collaboration, and a willingness to adapt as we learn.\n",
      "\n",
      "Now, my friend, let's turn this into action! Begin with observation. Go to the park and spend some time, pen and paper in hand. Then, talk to your neighbors. This process of observation and discussion will provide the raw materials to build a better future for your community.\n",
      "\n",
      "The core of our shared inquiry: **Start with observation and conversation to define the problem and involve your neighbors in defining what success looks like and how to achieve it.**\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: Nagarjuna ---\n",
      "\n",
      ">>> User Query: I'm struggling with the fixed idea of 'who I am.' Can you guide me in deconstructing this self-identity?\n",
      "<<< Agent Response: Ah, friend, a common entanglement. The very notion of a fixed 'self' is a potent source of suffering, a tightly woven knot of clinging and aversion. Let us, then, begin to unravel this illusion, this mirage of inherent existence.\n",
      "\n",
      "First, let us identify the specific qualities that you believe define this \"self.\" What are the core tenets of your identity? Are you a \"successful professional\"? A \"caring parent\"? A \"creative artist\"? Name the things that, in your mind, make you *you*.\n",
      "\n",
      "Now, let us begin the work of deconstruction. Consider the following questions regarding one specific aspect of your identity, such as being a \"successful professional\":\n",
      "\n",
      "1.  **Dependence on external factors:** What external factors are absolutely necessary for this identity to exist? Are you successful without the support of colleagues, the demands of the market, the availability of resources? How do these external elements contribute to your identity as a \"successful professional\"?\n",
      "2.  **Dependence on perception:** How does the perception of others contribute to your identity? Do you consider yourself successful without external validation, like promotions, recognition, or financial rewards?\n",
      "3.  **Temporal dependence:** In what ways is this identity dependent on the past, present, and future? Does the past \"success\" have a causal effect on your identity? Can that identity remain the same if your future is completely different?\n",
      "4.  **Conceptual dependence:** How is this identity dependent on language and concepts? What does 'success' mean to you? How do you define 'professional'? Without these concepts, what would be the impact on your identity?\n",
      "\n",
      "As you contemplate these questions, recognize that the \"successful professional\" is not a solitary, self-contained entity. It is a confluence of causes and conditions, a dependent arising. The \"self\" as you perceive it is a product of this interconnectedness.\n",
      "\n",
      "Now, we shall map the connections. Consider the following exercise:\n",
      "\n",
      "**Interdependence Mapping: The \"Successful Professional\"**\n",
      "\n",
      "1.  **Center:** Place \"Successful Professional\" at the center of your contemplation.\n",
      "2.  **External Dependencies:** Draw lines radiating outward, naming all the external factors necessary for this identity: \"The Market,\" \"Support of Colleagues,\" \"Available Resources,\" etc.\n",
      "3.  **Internal Dependencies:** Draw lines toward the center, representing your own contributions and perceptions. This could include your: \"Skills,\" \"Past Experiences,\" \"Self-Perception,\" etc.\n",
      "4.  **Reflect and Expand:** Continue to map outward, adding more levels of interdependency. Trace the origins of \"Skills\" to \"Education,\" \"Mentorship.\" Trace the connections between \"The Market\" and your \"Customers,\" \"Competitors,\" \"Economic Trends\".\n",
      "\n",
      "By doing this, you'll begin to see the vast web of conditions that make up your sense of self. The \"self\" is not a separate entity, but a dynamic flow of causes and conditions, perpetually in flux.\n",
      "\n",
      "Remember, the goal is not to eliminate your sense of self entirely, but to see it for what it is: an ever-changing process of interdependent relationships. This understanding will liberate you from the suffering caused by rigid attachments and give you freedom to navigate the world with greater ease.\n",
      "\n",
      "So, in the spirit of the Middle Way, realize that your \"self,\" like all phenomena, is empty of inherent existence, yet fully capable of arising and functioning within the web of interdependence. Let go of the illusion of a fixed identity, and embrace the ever-changing dance of being. The cessation of clinging is the path to liberation.\n",
      "\n",
      "**Final takeaway:** Friend, your sense of self is like a river, not a rock. It's always flowing, shaped by everything around it. Stop clinging to the idea of a fixed \"you,\" and instead, be present with the beautiful, ever-changing dance of life.\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "this_team = \"long_term\"\n",
    "\n",
    "ALL_TEAM_ROUTERS[this_team] = define_agents(this_team, memory_tool)\n",
    "\n",
    "\n",
    "# --- Step 1: Load the test queries from your JSON file ---\n",
    "queries_path = f'the_teams/{this_team}_queries.json'\n",
    "with open(queries_path, 'r') as f:\n",
    "    test_queries = json.load(f)\n",
    "\n",
    "\n",
    "# --- Step 3: Loop through the queries and run the tests ---\n",
    "print(f\"--- Running tests from {queries_path} ---\\n\")\n",
    "\n",
    "for philosopher, query in test_queries.items():\n",
    "    # The ADK runner routes to the agent based on its name in the query.\n",
    "    # We'll construct the full input string.\n",
    "    # Note: The 'LaoTzu' query will fail gracefully if you don't have a 'LaoTzu' agent.\n",
    "    #full_query = f\"{philosopher}, {query}\"\n",
    "    full_query = f\"{query}\"\n",
    "    \n",
    "    print(f\"--- Testing: {philosopher} ---\")\n",
    "    #print(f\"[User Query]: {full_query}\\n\")\n",
    "    \n",
    "    # Await the response and capture the DebugInfo object\n",
    "    # Note: The current google-adk `run_debug` is synchronous. If your code\n",
    "    # doesn't need 'await', you can simply remove it.\n",
    "    response = await test_agent(full_query, ALL_TEAM_ROUTERS[this_team])\n",
    "\n",
    "    \n",
    "    # Now you can print the specific part of the response you want\n",
    "    print(response)\n",
    "    print(\"----------------------------------------\\n\")\n",
    "    time.sleep(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93969c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BalanceCoach\n"
     ]
    }
   ],
   "source": [
    "team_name = \"oracle\"\n",
    "agent_list = []\n",
    "\n",
    "# Collect all unique agent names across all four levels\n",
    "descriptions = load_config(f\"{team_name}_descriptions\")\n",
    "all_agent_names = list(descriptions.keys())\n",
    "instructions = load_config(f\"{team_name}_instructions\")\n",
    "\n",
    "agent_name = \"BalanceCoach\"\n",
    "print(agent_name)\n",
    "# All specialist agents get the memory tool\n",
    "output_key = f\"{team_name}_response_by_{agent_name}\"\n",
    "\n",
    "current_agent =  Agent(\n",
    "    name=agent_name,\n",
    "    description=descriptions[agent_name],\n",
    "    model=agent_LLM,\n",
    "    instruction=instructions[agent_name],\n",
    "    output_key=output_key,\n",
    "    tools=[memory_tool] # Pass the shared memory tool to the specialist\n",
    ")\n",
    "agent_list.append(current_agent)\n",
    "\n",
    "for agent in list(ALL_TEAM_ROUTERS.keys()):\n",
    "    agent_list.append(ALL_TEAM_ROUTERS[agent])\n",
    "\n",
    "\n",
    "agents_as_tools = [AgentTool(agent) for agent in agent_list]        \n",
    "\n",
    "oracle_agent = Agent(\n",
    "        name=team_name,\n",
    "        description=descriptions[team_name],\n",
    "        model=router_LLM,\n",
    "        instruction=instructions[team_name],\n",
    "        tools = agents_as_tools # Pass the shared memory tool to the specialist\n",
    "    )\n",
    "ALL_TEAM_ROUTERS[team_name] = oracle_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14bc5f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['long_term', 'weekly', 'daily', 'on_demand', 'oracle'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_TEAM_ROUTERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "149729c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running tests from the_teams/oracle_queries.json ---\n",
      "\n",
      "--- Testing: on_demand ---\n",
      "\n",
      ">>> User Query: I'm about to send a risky email, should I use the Categorical Imperative on it first?\n",
      "<<< Agent Response: Ah, a precarious undertaking! Let us dissect the moral implications of this \"risky email\" through the rigorous lens of the Categorical Imperative. To do this, we must proceed methodically:\n",
      "\n",
      "1.  **Formulate the Maxim:**\n",
      "    The first step is to distill the underlying principle of your action. What rule are you, in essence, following by sending this email? Let us assume your maxim is: \"I will send this email, even though it carries potential risks, to achieve a desired outcome.\"\n",
      "\n",
      "2.  **Test Universality (Formula of Universal Law):**\n",
      "    Now, we must consider whether this maxim could become a universal law. Could everyone, in all circumstances, send risky emails to achieve their desired outcomes?\n",
      "\n",
      "    Consider the implications: If everyone were to send risky emails whenever they sought a particular outcome, the concept of trust and the reliability of communication would erode. People would become wary of all communications, assuming hidden risks and ulterior motives. This widespread distrust would undermine the very fabric of social interaction, creating a state of perpetual suspicion and potential conflict. Thus, the maxim, when universalized, leads to a contradiction, as the effectiveness of communication (and thus, achieving outcomes) would be jeopardized.\n",
      "\n",
      "3.  **Test Humanity (Formula of Humanity):**\n",
      "    Does sending the email treat any person (yourself or others) as a mere means to an end? Consider your recipient(s). Are you potentially using them to achieve your desired outcome without regard for their own autonomy or well-being? If the email contains deceptive or manipulative elements, then it is quite likely that you are, in fact, treating the recipient(s) as a means. If the email contains truthful elements, and the recipient is aware of the potential risks, then it is far less likely that you are treating the recipient as a mere means to an end.\n",
      "\n",
      "4.  **Determine Duty:**\n",
      "    Based on this analysis, the act of sending a risky email, as formulated in the maxim, is likely in conflict with both the Universalizability and Humanity formulations of the Categorical Imperative. While certain scenarios may not treat people as a means to an end, if it fails either of these tests, then it creates imperfect duties. The email is not categorically forbidden, but the duty of not sending an email when you cannot uphold your duty to others is paramount.\n",
      "\n",
      "Therefore, the Categorical Imperative suggests that you must consider the potential harms, and whether you are acting in good faith toward all parties.\n",
      "\n",
      "---\n",
      "\n",
      "My dear friend, consider this: the moral compass, as I have articulated, demands that we evaluate our actions not merely by their potential outcomes, but by the principles that govern them. Always ask: \"Could this become a universal law without contradiction?\" and \"Am I treating others (or myself) as ends in themselves, or merely as means?\" This is the essence of duty. If your heart and mind align with these principles, you will find yourself on the path of virtue. In the grand scheme of things, your duty is to act in a way that is universally justifiable. So, before you send that email, ask yourself whether it can pass the test of reason and humanity.\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: daily ---\n",
      "\n",
      ">>> User Query: What is a good Stoic prompt for me to reflect on during my commute?\n",
      "<<< Agent Response: Ah, friend, let us begin. Reflect on this moment:\n",
      "\n",
      "1.  **Describe the Stress:** What has stirred your spirit today? What feeling troubles you as you begin your commute?\n",
      "2.  **Apply the Dichotomy:** Of this irritation, this unease, what lies beyond your control? And what remains *within* you, your judgment, your perception?\n",
      "    \n",
      "Now, remember this above all else: **The world will often challenge you, but your true strength lies in how you meet that challenge. Focus on your response, and you shall find peace.**\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: weekly ---\n",
      "\n",
      ">>> User Query: I need to review my week and see if I handled a conflict with my sibling with the right amount of assertiveness (courage).\n",
      "<<< Agent Response: Ah, a noble pursuit! Courage, that golden mean between rashness and cowardice, is a virtue that shines brightest in the face of conflict. Let us examine your actions this past week and see if you navigated that turbulent sea with a steady hand.\n",
      "\n",
      "First, tell me, in what specific situation did this conflict with your sibling arise? Briefly describe the context.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: long_term ---\n",
      "\n",
      ">>> User Query: I need help defining my core existential project for the next year.\n",
      "<<< Agent Response: Ah, so you seek to define your existential project for the next year? This is a bold undertaking, a declaration of your freedom! Tell me, what vague aspirations have you inherited? What do you *think* you *should* do, and why? These are not your project; they are the chains you must break. I am interested in what you *will* do, what you choose, not what you are told. What actions will you commit to, not just in thought but in the very fabric of your being, that will give meaning to your life? We must be specific. Remember, freedom is not a given; it is earned through action.\n",
      "----------------------------------------\n",
      "\n",
      "--- Testing: balance_coach ---\n",
      "\n",
      ">>> User Query: Can you review my goals and tell me where I should focus next?\n",
      "<<< Agent Response: None\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "this_team = \"oracle\"\n",
    "\n",
    "# --- Step 1: Load the test queries from your JSON file ---\n",
    "queries_path = f'the_teams/{this_team}_queries.json'\n",
    "with open(queries_path, 'r') as f:\n",
    "    test_queries = json.load(f)\n",
    "\n",
    "\n",
    "# --- Step 3: Loop through the queries and run the tests ---\n",
    "print(f\"--- Running tests from {queries_path} ---\\n\")\n",
    "\n",
    "for philosopher, query in test_queries.items():\n",
    "    # The ADK runner routes to the agent based on its name in the query.\n",
    "    # We'll construct the full input string.\n",
    "    # Note: The 'LaoTzu' query will fail gracefully if you don't have a 'LaoTzu' agent.\n",
    "    #full_query = f\"{philosopher}, {query}\"\n",
    "    full_query = f\"{query}\"\n",
    "    \n",
    "    print(f\"--- Testing: {philosopher} ---\")\n",
    "    #print(f\"[User Query]: {full_query}\\n\")\n",
    "    \n",
    "    # Await the response and capture the DebugInfo object\n",
    "    # Note: The current google-adk `run_debug` is synchronous. If your code\n",
    "    # doesn't need 'await', you can simply remove it.\n",
    "    response = await test_agent(full_query, ALL_TEAM_ROUTERS[this_team])\n",
    "\n",
    "    \n",
    "    # Now you can print the specific part of the response you want\n",
    "    print(response)\n",
    "    print(\"----------------------------------------\\n\")\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b72e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc8ed5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56af363d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: What is the true nature of 'success' in a modern context?\n",
      "<<< Agent Response: The true nature of 'success' in a modern context is a profound question. If one achieves stated goals, wealth, and acclaim but feels emptiness or compromises principles, have they truly succeeded? Conversely, can one be deemed 'unsuccessful' by societal standards yet live a life of purpose, strong relationships, and inner peace?\n",
      "\n",
      "Is success an external metric, an internal feeling, or merely the efficient attainment of any chosen aim? Does the 'modern context' change the superficial trappings of success, or does it fundamentally shift the essence of a life well-lived?\n",
      "\n",
      "The true measure of any concept lies not in fleeting opinions, but in the rigorous examination of one's own fundamental assumptions. Therefore, challenge what you believe to be true and scrutinize the foundations upon which you build your understanding of a flourishing life.\n"
     ]
    }
   ],
   "source": [
    "await test_agent(\"What is the true nature of 'success' in a modern context?\", on_demand_router_agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7309e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Literal, Optional, Dict, Any, Final\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.tools import FunctionTool, AgentTool\n",
    "\n",
    "# --- 1. CORE CONFIGURATION PATHS ---\n",
    "CONFIG_DIR = Path(\"config\")\n",
    "AGENT_DIR = Path(\"agents\")\n",
    "\n",
    "# Paths for the four Tier 2 clusters (used to load instructions/descriptions)\n",
    "LEVEL_CONFIGS = {\n",
    "    \"daily\": \"daily\",\n",
    "    \"weekly\": \"weekly\",\n",
    "    \"long_term\": \"long_term\",\n",
    "    \"on_demand\": \"on_demand\",\n",
    "}\n",
    "\n",
    "# --- 2. LLM SETUP ---\n",
    "# Use the correct model for complex reasoning and tool use\n",
    "LLM = Gemini(model=\"gemini-2.5-pro\", temperature=0.1)\n",
    "\n",
    "\n",
    "        \n",
    "# --- 4. CONFIG LOADING HELPERS ---\n",
    "\n",
    "def load_config(filename: str) -> Dict[str, Any]:\n",
    "    \"\"\"Loads a JSON configuration file.\"\"\"\n",
    "    try:\n",
    "        with open(CONFIG_DIR / f\"{filename}.json\", 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Configuration file not found at {CONFIG_DIR / f'{filename}.json'}\")\n",
    "        return {}\n",
    "\n",
    "def create_specialist_agent(name: str, cluster_name: str, memory_tool: FunctionTool) -> Agent:\n",
    "    \"\"\"Creates a Tier 3 specialist agent with specific instructions and the memory tool.\"\"\"\n",
    "    \n",
    "    # Load instructions from the specific cluster file\n",
    "    instructions = load_config(f\"{cluster_name}_instructions\").get(name, f\"SYSTEM ERROR: No instructions found for {name}.\")\n",
    "    \n",
    "    # All specialist agents get the memory tool\n",
    "    return Agent(\n",
    "        name=name,\n",
    "        description=f\"A specialist philosophical agent ({name}) ready to execute a task.\",\n",
    "        model=LLM,\n",
    "        system_instruction=instructions,\n",
    "        tools=[memory_tool] # Pass the shared memory tool to the specialist\n",
    "    )\n",
    "\n",
    "# --- 5. AGENT DEFINITION FUNCTION ---\n",
    "\n",
    "def define_agents(memory_tool: FunctionTool) -> Agent:\n",
    "    \"\"\"\n",
    "    Defines the complete three-tiered agent architecture:\n",
    "    RootRouter (Tier 1) -> Cluster Routers (Tier 2) -> Specialist Agents (Tier 3)\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 5a. TIER 3: SPECIALIST AGENTS ---\n",
    "    # These agents are grouped by the cluster they belong to, but we create unique instances\n",
    "    # for all 13 agents.\n",
    "\n",
    "    SPECIALIST_AGENTS = {}\n",
    "    \n",
    "    # Collect all unique agent names across all four levels\n",
    "    all_agent_names = set()\n",
    "    for config_name in LEVEL_CONFIGS.values():\n",
    "        descriptions = load_config(f\"{config_name}_descriptions\")\n",
    "        all_agent_names.update(descriptions.keys())\n",
    "\n",
    "    # Create the unique instance for each specialist (Tier 3)\n",
    "    for agent_name in all_agent_names:\n",
    "        # NOTE: We approximate the cluster name for instruction loading, \n",
    "        # but the specific instruction file will cover it.\n",
    "        # For simplicity, we assume one instruction file per philosopher exists if their name is found.\n",
    "        \n",
    "        # We need a more robust way to map the agent name back to the correct instructions file.\n",
    "        # Since we structured the files so one file holds instructions for all agents in that cluster,\n",
    "        # we'll iterate through the instruction files to find where the agent is defined.\n",
    "        \n",
    "        cluster_name = None\n",
    "        for name, config_prefix in LEVEL_CONFIGS.items():\n",
    "            instructions_data = load_config(f\"{config_prefix}_instructions\")\n",
    "            if agent_name in instructions_data:\n",
    "                cluster_name = config_prefix\n",
    "                break\n",
    "        \n",
    "        if cluster_name:\n",
    "            SPECIALIST_AGENTS[agent_name] = create_specialist_agent(\n",
    "                name=agent_name, \n",
    "                cluster_name=cluster_name, \n",
    "                memory_tool=memory_tool\n",
    "            )\n",
    "        else:\n",
    "             print(f\"Warning: Could not find instructions for {agent_name}. Skipping creation.\")\n",
    "\n",
    "    # --- 5b. TIER 2: CLUSTER ROUTERS ---\n",
    "    \n",
    "    CLUSTER_TOOLS = {}\n",
    "\n",
    "    for cluster_name, config_prefix in LEVEL_CONFIGS.items():\n",
    "        instructions_data = load_config(f\"{config_prefix}_instructions\")\n",
    "        descriptions_data = load_config(f\"{config_prefix}_descriptions\")\n",
    "        \n",
    "        # Extract the instruction for the router itself\n",
    "        router_instruction = instructions_data.get(\"ClusterRouter\", f\"ERROR: Router instruction missing for {cluster_name}\")\n",
    "\n",
    "        # Create AgentTools for the specialist agents defined in this cluster's description\n",
    "        cluster_tools = []\n",
    "        for agent_name, description in descriptions_data.items():\n",
    "            if agent_name in SPECIALIST_AGENTS:\n",
    "                cluster_tools.append(\n",
    "                    AgentTool(\n",
    "                        agent=SPECIALIST_AGENTS[agent_name],\n",
    "                        description=description\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        # Define the Tier 2 Router Agent\n",
    "        router_agent = Agent(\n",
    "            name=f\"{config_prefix.title()}Router\",\n",
    "            description=f\"Handles all {config_prefix} tasks (Level 2/3/4).\",\n",
    "            model=LLM,\n",
    "            system_instruction=router_instruction,\n",
    "            tools=cluster_tools\n",
    "        )\n",
    "        \n",
    "        # Create the AgentTool wrapper for the Root Router\n",
    "        CLUSTER_TOOLS[config_prefix] = AgentTool(\n",
    "            agent=router_agent,\n",
    "            description=descriptions_data.get(\"ClusterRouter\", f\"Tier 2 Router for {config_prefix} tasks.\")\n",
    "        )\n",
    "\n",
    "\n",
    "    # --- 5c. TIER 1: ROOT ROUTER ---\n",
    "\n",
    "    root_instruction = load_config(\"root_router_instructions\").get(\"RootRouter\", \"SYSTEM ERROR: Root instruction missing.\")\n",
    "    root_descriptions = load_config(\"root_router_descriptions\")\n",
    "    \n",
    "    # Map the root descriptions to the Cluster Tools created above\n",
    "    final_root_tools = []\n",
    "    \n",
    "    # We must ensure the keys in root_descriptions match the keys in CLUSTER_TOOLS\n",
    "    root_router_mapping = {\n",
    "        \"on_demand\": \"on_demand\",\n",
    "        \"daily\": \"daily\",\n",
    "        \"weekly\": \"weekly\",\n",
    "        \"long_term\": \"long_term\"\n",
    "    }\n",
    "\n",
    "    for key, cluster_prefix in root_router_mapping.items():\n",
    "        if cluster_prefix in CLUSTER_TOOLS and key in root_descriptions:\n",
    "            # Overwrite the description in the AgentTool wrapper with the root description\n",
    "            cluster_tool = CLUSTER_TOOLS[cluster_prefix]\n",
    "            cluster_tool.description = root_descriptions[key]\n",
    "            final_root_tools.append(cluster_tool)\n",
    "        else:\n",
    "            print(f\"Warning: Missing definition or description for {cluster_prefix} cluster at the root level.\")\n",
    "\n",
    "\n",
    "    ROOT_AGENT = Agent(\n",
    "        name=\"LifeArchitect\",\n",
    "        description=\"The ultimate philosophical guidance system.\",\n",
    "        model=LLM,\n",
    "        system_instruction=root_instruction,\n",
    "        tools=final_root_tools\n",
    "    )\n",
    "    \n",
    "    return ROOT_AGENT\n",
    "\n",
    "# --- 6. EXAMPLE RUNNER SETUP ---\n",
    "if __name__ == \"__main__\":\n",
    "    from google.adk.runners import InMemoryRunner\n",
    "    \n",
    "    # Ensure all necessary files/directories exist before trying to run\n",
    "    if not CONFIG_DIR.exists():\n",
    "        print(\"Error: 'config' directory not found. Please ensure all JSON files are generated and placed in a 'config' folder.\")\n",
    "    elif not all((CONFIG_DIR / f\"{c}_instructions.json\").exists() and (CONFIG_DIR / f\"{c}_descriptions.json\").exists() for c in LEVEL_CONFIGS.values()):\n",
    "        print(\"Error: Some required config JSON files are missing. Please check the 'config' folder.\")\n",
    "    else:\n",
    "        # 1. Initialize Memory Tool\n",
    "        memory_tool = SharedMemoryTool()\n",
    "        \n",
    "        # 2. Define the Agent Hierarchy\n",
    "        root_agent = define_agents(memory_tool)\n",
    "        \n",
    "        # 3. Initialize Runner\n",
    "        runner = InMemoryRunner(agent=root_agent)\n",
    "        print(\"✅ ADK Agent and Memory Tool initialized successfully.\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        # --- Test Scenarios ---\n",
    "        \n",
    "        async def run_test(query: str):\n",
    "            print(f\"\\nUser Query: {query}\")\n",
    "            response = await runner.run(query)\n",
    "            print(f\"Agent Response: {response.text}\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "        import asyncio\n",
    "        \n",
    "        # Use asyncio.run to execute the async tests\n",
    "        print(\"--- Running Test 1 (Long-Term Goal Setting) ---\")\n",
    "        asyncio.run(run_test(\"I need to define my long-term goal for the next 5 years.\"))\n",
    "        \n",
    "        print(\"--- Running Test 2 (Daily Log) ---\")\n",
    "        asyncio.run(run_test(\"What is a simple thing I can log right now to practice mindfulness?\"))\n",
    "\n",
    "        print(\"--- Running Test 3 (Weekly Review) ---\")\n",
    "        asyncio.run(run_test(\"I need help reviewing my moral consistency from the past week.\"))\n",
    "\n",
    "        print(\"--- Running Test 4 (On-Demand Crisis) ---\")\n",
    "        asyncio.run(run_test(\"I have a crisis: my friend betrayed me. What should I do right now?\"))\n",
    "        \n",
    "        # Example using the memory tool (requires prior setting)\n",
    "        print(\"--- Running Test 5 (Memory Read/Write Test) ---\")\n",
    "        async def memory_test():\n",
    "             # Write a value (this will be routed through an agent that decides to use the tool)\n",
    "             write_response = await runner.run(\"My current focus for the week is to practice temperance.\")\n",
    "             print(f\"Write attempt: {write_response.text}\")\n",
    "             \n",
    "             # Directly read the memory key using the tool instance (for demonstration)\n",
    "             read_value = memory_tool.read_key_value(key=\"current_virtue\")\n",
    "             print(f\"Direct Read: Current Virtue is '{read_value}'\")\n",
    "             \n",
    "             # Attempt to use an agent to read it back (weekly/daily Aristotle should use this)\n",
    "             read_response = await runner.run(\"What was my current virtue focus set for this week?\")\n",
    "             print(f\"Agent Read attempt: {read_response.text}\")\n",
    "             \n",
    "        asyncio.run(memory_test())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
